{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwy5qzeeSLFa",
        "outputId": "09e28441-833b-4c7d-80c0-d3c73ed43279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "import bz2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import keras\n",
        "\n",
        "\n",
        "df = pd.read_csv('preprocessed_data 2.csv', header=0)\n",
        "df_model = df\n",
        "print(df_model.columns)\n",
        "df_train, df_test = train_test_split(df_model, test_size=0.2, random_state=42)\n",
        "print(df_train.columns)\n",
        "\n",
        "df_train.head(2)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vectorize text using TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df=.01) #(ngram_range=(1,2),min_df=2, max_features = 10000, min_df=.01)\n",
        "# Convert a collection of raw documents to a matrix of TF-IDF term features. fit_transform() on TRAIN data\n",
        "train_tfidf_matrix = tfidf.fit_transform(df_train[\"clean_text_4\"].values)\n",
        "\n",
        "# transform() on TEST data\n",
        "# Using the transform method we can use the same mean and variance as it is calculated from our training data to transform our test data. Thus, the parameters learned by our model using the training data will help us to transform our test data.\n",
        "test_tfidf_matrix = tfidf.transform(df_test[\"clean_text_4\"].values)\n",
        "# Extract feature_names\n",
        "terms_features = tfidf.get_feature_names_out()\n",
        "print(len(terms_features))\n",
        "print(terms_features[0:10])\n",
        "train_tfidf_vector = train_tfidf_matrix.toarray()\n",
        "test_tfidf_vector = test_tfidf_matrix.toarray()\n",
        "result = pd.DataFrame(data=train_tfidf_matrix.toarray(), columns=terms_features)\n",
        "print(result.head(5))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['rating', 'title', 'text', 'language', 'language_label', 'label',\n",
            "       'clean_text_1', 'clean_text_2', 'clean_text_4', 'clean_text_5',\n",
            "       'final_text'],\n",
            "      dtype='object')\n",
            "Index(['rating', 'title', 'text', 'language', 'language_label', 'label',\n",
            "       'clean_text_1', 'clean_text_2', 'clean_text_4', 'clean_text_5',\n",
            "       'final_text'],\n",
            "      dtype='object')\n",
            "672\n",
            "['able' 'about' 'absolutely' 'acting' 'action' 'actually' 'add' 'after'\n",
            " 'again' 'against']\n",
            "   able     about  absolutely  acting  action  actually  add    after  again  \\\n",
            "0   0.0  0.000000         0.0     0.0     0.0       0.0  0.0  0.00000    0.0   \n",
            "1   0.0  0.114633         0.0     0.0     0.0       0.0  0.0  0.00000    0.0   \n",
            "2   0.0  0.000000         0.0     0.0     0.0       0.0  0.0  0.00000    0.0   \n",
            "3   0.0  0.118789         0.0     0.0     0.0       0.0  0.0  0.14214    0.0   \n",
            "4   0.0  0.000000         0.0     0.0     0.0       0.0  0.0  0.00000    0.0   \n",
            "\n",
            "   against  ...  written  wrong  year  years  yes  yet       you  young  \\\n",
            "0      0.0  ...      0.0    0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
            "1      0.0  ...      0.0    0.0   0.0    0.0  0.0  0.0  0.086986    0.0   \n",
            "2      0.0  ...      0.0    0.0   0.0    0.0  0.0  0.0  0.284838    0.0   \n",
            "3      0.0  ...      0.0    0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
            "4      0.0  ...      0.0    0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
            "\n",
            "       your  yourself  \n",
            "0  0.000000       0.0  \n",
            "1  0.133565       0.0  \n",
            "2  0.000000       0.0  \n",
            "3  0.000000       0.0  \n",
            "4  0.000000       0.0  \n",
            "\n",
            "[5 rows x 672 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rnn model\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(train_tfidf_vector,df_train['rating'])\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units = 256, activation = 'relu', input_shape=(672,)))\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu',kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(units=64, activation='relu',kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=6, activation='softmax'))"
      ],
      "metadata": {
        "id": "6JxNTIIRzIzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'SGD',\n",
        "             loss= 'sparse_categorical_crossentropy',\n",
        "             metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRPvThK8zR-y",
        "outputId": "33d04f9d-6e7a-4cea-995b-ef60b458efc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_53 (Dense)            (None, 256)               172288    \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213830 (835.27 KB)\n",
            "Trainable params: 213830 (835.27 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "Tc-DILVczVBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c308a7c7-05d1-44c5-c6f8-8070c0869e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4676/4676 [==============================] - 21s 4ms/step - loss: 1.6791 - sparse_categorical_accuracy: 0.2432\n",
            "Epoch 2/10\n",
            "4676/4676 [==============================] - 22s 5ms/step - loss: 1.4590 - sparse_categorical_accuracy: 0.3853\n",
            "Epoch 3/10\n",
            "4676/4676 [==============================] - 20s 4ms/step - loss: 1.3617 - sparse_categorical_accuracy: 0.4384\n",
            "Epoch 4/10\n",
            "4676/4676 [==============================] - 20s 4ms/step - loss: 1.3410 - sparse_categorical_accuracy: 0.4474\n",
            "Epoch 5/10\n",
            "4676/4676 [==============================] - 23s 5ms/step - loss: 1.3315 - sparse_categorical_accuracy: 0.4516\n",
            "Epoch 6/10\n",
            "4676/4676 [==============================] - 20s 4ms/step - loss: 1.3243 - sparse_categorical_accuracy: 0.4541\n",
            "Epoch 7/10\n",
            "4676/4676 [==============================] - 21s 5ms/step - loss: 1.3184 - sparse_categorical_accuracy: 0.4582\n",
            "Epoch 8/10\n",
            "4676/4676 [==============================] - 20s 4ms/step - loss: 1.3136 - sparse_categorical_accuracy: 0.4586\n",
            "Epoch 9/10\n",
            "4676/4676 [==============================] - 20s 4ms/step - loss: 1.3088 - sparse_categorical_accuracy: 0.4608\n",
            "Epoch 10/10\n",
            "4676/4676 [==============================] - 21s 4ms/step - loss: 1.3051 - sparse_categorical_accuracy: 0.4617\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78ec91731420>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prKtG3GmzXwq",
        "outputId": "d2014a40-602b-4892-bd86-e5b49908281a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1559/1559 [==============================] - 3s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(y_pred)\n",
        "print(y_test.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViQOX8QEW5nm",
        "outputId": "85bf7d2d-ddec-4116-9dd1-094c8eab0d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 4 2 ... 5 5 4]\n",
            "[1 3 2 ... 3 5 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "cn = confusion_matrix(y_test.values,y_pred)\n",
        "print(cn)\n",
        "\n",
        "acc_cm = accuracy_score(y_test.values, y_pred)\n",
        "print(acc_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj2H6mwvUSlP",
        "outputId": "c915393f-ddd7-4bee-dafe-7b7c74cf0a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7393 2399 1076  569  918]\n",
            " [3226 4359 2991 1110  857]\n",
            " [1331 2523 4654 2695 1151]\n",
            " [ 780  919 2516 4732 3580]\n",
            " [ 897  527  762 2413 7968]]\n",
            "0.4668463093061303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model= LogisticRegression(multi_class='multinomial',max_iter=1000, penalty='l2').fit(train_tfidf_vector,df_train['rating'])\n",
        "\n",
        "# prediction based on model trained\n",
        "\n",
        "y_pred=model.predict(test_tfidf_vector)\n",
        "\n",
        "\"\"\"\n",
        "In order to train the model, the method Logistic Regression was implemented. In particular,  multiclass configuration was set as the target variable had more than 3 variables.\n",
        "\n",
        "Regularization L2, or ridge, was used to prevent overfiting.\n",
        "\n",
        "This code is performing a logistic regression on the dataset that has been transformed using TF-IDF.\n",
        "\"\"\"\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "cn = confusion_matrix(df_test['rating'],y_pred )\n",
        "print(cn)\n",
        "\n",
        "acc_cm = accuracy_score(df_test['rating'], y_pred)\n",
        "print(acc_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Qy5S7nTtoE",
        "outputId": "72d161ef-994e-4d62-8a2c-f7c9e7eab5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "[[5898 2009  781  439  722]\n",
            " [2617 3522 2243  915  658]\n",
            " [1100 2109 3799 2153  906]\n",
            " [ 638  766 1960 3694 2856]\n",
            " [ 727  399  595 1952 6419]]\n",
            "0.46779076528259517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multinomial Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()\n",
        "nb.fit(train_tfidf_vector,df_train['rating'])\n",
        "preds = nb.predict(test_tfidf_vector)\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(confusion_matrix(df_test['rating'], preds))\n",
        "print('\\n')\n",
        "print(classification_report(df_test['rating'], preds))\n",
        "cn = confusion_matrix(df_test['rating'],preds )\n",
        "print(cn)\n",
        "\n",
        "acc_cm = accuracy_score(df_test['rating'], preds)\n",
        "print(acc_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOIksNHPzXz7",
        "outputId": "cb8460cd-429c-434a-dc14-71c46e4934d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5603 2087  810  559  790]\n",
            " [2608 3302 2306 1005  734]\n",
            " [1365 1834 3670 2214  984]\n",
            " [ 814  791 1979 3499 2831]\n",
            " [ 866  470  662 1946 6148]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.57      0.53      9849\n",
            "           2       0.39      0.33      0.36      9955\n",
            "           3       0.39      0.36      0.38     10067\n",
            "           4       0.38      0.35      0.37      9914\n",
            "           5       0.54      0.61      0.57     10092\n",
            "\n",
            "    accuracy                           0.45     49877\n",
            "   macro avg       0.44      0.45      0.44     49877\n",
            "weighted avg       0.44      0.45      0.44     49877\n",
            "\n",
            "[[5603 2087  810  559  790]\n",
            " [2608 3302 2306 1005  734]\n",
            " [1365 1834 3670 2214  984]\n",
            " [ 814  791 1979 3499 2831]\n",
            " [ 866  470  662 1946 6148]]\n",
            "0.4455360186057702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic regression with concatenation\n",
        "\n",
        "import scipy.sparse as sp\n",
        "#matrix and dataframe  concatenation\n",
        "x=sp.vstack((train_tfidf_matrix,test_tfidf_matrix))\n",
        "\n",
        "y=pd.concat([df_train['rating'], df_test['rating']])\n",
        "\n",
        "#spliting data\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y)\n",
        "\n",
        "#model training to logistic regression for multiple values and ridge penalty\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model= LogisticRegression(multi_class='multinomial', max_iter=1000, penalty='l2').fit(x_train,y_train)\n",
        "\n",
        "# prediction based on model trained\n",
        "print(model.predict_proba(x_test))\n",
        "y_pred=model.predict(x_test)\n",
        "\n",
        "\"\"\"\n",
        "In order to train the model, the method Logistic Regression was implemented. In particular,  multiclass configuration was set as the target variable had more than 3 variables.\n",
        "\n",
        "Regularization L2, or ridge, was used to prevent overfiting.\n",
        "\n",
        "This code is performing a logistic regression on the dataset that has been transformed using TF-IDF.\n",
        "\"\"\"\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "cn = confusion_matrix(y_test,y_pred )\n",
        "print(cn)\n",
        "\n",
        "acc_cm = accuracy_score(y_test, y_pred)\n",
        "print(acc_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu39aYyYoMZD",
        "outputId": "52d827fe-9cf6-44b2-83de-2fc1ad42f1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00124018 0.00418158 0.01934015 0.29190451 0.68333358]\n",
            " [0.10323997 0.15567941 0.1729058  0.31656558 0.25160925]\n",
            " [0.22921159 0.08653493 0.02255524 0.14749463 0.51420362]\n",
            " ...\n",
            " [0.03332114 0.11380455 0.15135416 0.21212376 0.48939639]\n",
            " [0.05560014 0.14368521 0.42281847 0.31805128 0.05984491]\n",
            " [0.16890622 0.27957516 0.34870258 0.09585785 0.10695819]]\n",
            "[[7520 2424 1021  534  909]\n",
            " [3270 4363 2837 1144  792]\n",
            " [1366 2648 4628 2667 1116]\n",
            " [ 830  954 2403 4786 3493]\n",
            " [ 869  509  777 2431 8055]]\n",
            "0.4707920315657781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train,y_train)\n",
        "preds = nb.predict(x_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dn5r-dHYzI8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#Multinomial Naive Bayes with concatenation\n",
        "\n",
        "print(confusion_matrix(y_test, preds))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, preds))\n",
        "cn = confusion_matrix(y_test,preds )\n",
        "print(cn)\n",
        "cn = confusion_matrix(y_test,preds )\n",
        "print(cn)\n",
        "\n",
        "acc_cm = accuracy_score(y_test, preds)\n",
        "print(acc_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO0WJyG1a66V",
        "outputId": "4b437eef-aa36-4532-aad5-7d955f7d0e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7066 2600 1096  642 1004]\n",
            " [3269 4073 2949 1194  921]\n",
            " [1652 2327 4512 2677 1257]\n",
            " [1051  946 2494 4429 3546]\n",
            " [1059  605  828 2409 7740]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.57      0.53     12408\n",
            "           2       0.39      0.33      0.35     12406\n",
            "           3       0.38      0.36      0.37     12425\n",
            "           4       0.39      0.36      0.37     12466\n",
            "           5       0.53      0.61      0.57     12641\n",
            "\n",
            "    accuracy                           0.45     62346\n",
            "   macro avg       0.44      0.45      0.44     62346\n",
            "weighted avg       0.44      0.45      0.44     62346\n",
            "\n",
            "[[7066 2600 1096  642 1004]\n",
            " [3269 4073 2949 1194  921]\n",
            " [1652 2327 4512 2677 1257]\n",
            " [1051  946 2494 4429 3546]\n",
            " [1059  605  828 2409 7740]]\n",
            "[[7066 2600 1096  642 1004]\n",
            " [3269 4073 2949 1194  921]\n",
            " [1652 2327 4512 2677 1257]\n",
            " [1051  946 2494 4429 3546]\n",
            " [1059  605  828 2409 7740]]\n",
            "0.4462194848105733\n"
          ]
        }
      ]
    }
  ]
}