{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>language_label</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text_1</th>\n",
       "      <th>clean_text_2</th>\n",
       "      <th>clean_text_4</th>\n",
       "      <th>clean_text_5</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mens ultrasheer</td>\n",
       "      <td>This model may be ok for sedentary types, but ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>This model may be ok for sedentary types, but ...</td>\n",
       "      <td>This model may be ok for sedentary types , but...</td>\n",
       "      <td>this model may be ok for sedentary types  but ...</td>\n",
       "      <td>model may ok sedentary type active get alot jo...</td>\n",
       "      <td>model may ok sedentary type active get alot jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Surprisingly delightful</td>\n",
       "      <td>This is a fast read filled with unexpected hum...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "      <td>This is a fast read filled with unexpected hum...</td>\n",
       "      <td>This is a fast read filled with unexpected hum...</td>\n",
       "      <td>this is  fast read filled with unexpected humo...</td>\n",
       "      <td>fast read filled unexpected humour profound in...</td>\n",
       "      <td>fast read filled unexpected humour profound in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Works, but not as advertised</td>\n",
       "      <td>I bought one of these chargers..the instructio...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>I bought one of these chargers..the instructio...</td>\n",
       "      <td>I bought one of these chargers .. the instruct...</td>\n",
       "      <td>bought one of these chargers  the instruction...</td>\n",
       "      <td>bought one charger instruction say light stay ...</td>\n",
       "      <td>bought one charger instruction say light stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Oh dear</td>\n",
       "      <td>I was excited to find a book ostensibly about ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>I was excited to find a book ostensibly about ...</td>\n",
       "      <td>I was excited to find a book ostensibly about ...</td>\n",
       "      <td>was excited to find  book ostensibly about fe...</td>\n",
       "      <td>excited find book ostensibly feminism volume n...</td>\n",
       "      <td>excited find book ostensibly feminism volume n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Incorrect disc!</td>\n",
       "      <td>I am a big JVC fan, but I do not like this mod...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>I am a big JVC fan, but I do not like this mod...</td>\n",
       "      <td>I am a big fan , but I do not like this model ...</td>\n",
       "      <td>am  big fan  but  do not like this model   wa...</td>\n",
       "      <td>big fan not model suspiscious saw several unit...</td>\n",
       "      <td>big fan not model suspiscious saw several unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249379</th>\n",
       "      <td>3</td>\n",
       "      <td>3 stars plus.</td>\n",
       "      <td>Spellbound was Paula Abduls peak, Although its...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>Spellbound was Paula Abduls peak, Although its...</td>\n",
       "      <td>was Abduls peak , Although its her nd # album ...</td>\n",
       "      <td>was abduls peak  although its her nd  album  s...</td>\n",
       "      <td>abduls peak nd album selling million copy thin...</td>\n",
       "      <td>abduls peak nd album selling million copy thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249380</th>\n",
       "      <td>3</td>\n",
       "      <td>It's ok</td>\n",
       "      <td>This is my second purchase of this album used,...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second purchase of this album used,...</td>\n",
       "      <td>This is my purchase of this album used , lmao ...</td>\n",
       "      <td>this is my purchase of this album used  lmao  ...</td>\n",
       "      <td>purchase album used lmao music style changed m...</td>\n",
       "      <td>purchase album used lmao music style changed m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249381</th>\n",
       "      <td>2</td>\n",
       "      <td>Not Great But Not Awful</td>\n",
       "      <td>This product would be a good buy for under $10...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>This product would be a good buy for under $. ...</td>\n",
       "      <td>This product would be a good buy for under $ ....</td>\n",
       "      <td>this product would be  good buy for under   th...</td>\n",
       "      <td>product would good buy completed robot go shor...</td>\n",
       "      <td>product would good buy completed robot go shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249382</th>\n",
       "      <td>5</td>\n",
       "      <td>Greatest movie ever</td>\n",
       "      <td>I love the movie the five heart beats I think ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "      <td>I love the movie the five heart beats I think ...</td>\n",
       "      <td>I love the movie the heart beats I think it wa...</td>\n",
       "      <td>love the movie the heart beats  think it was ...</td>\n",
       "      <td>love movie heart beat think one gratest movie ...</td>\n",
       "      <td>love movie heart beat think one gratest movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249383</th>\n",
       "      <td>5</td>\n",
       "      <td>A cookbook for the imagination!</td>\n",
       "      <td>There's really not a lot of good material on t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "      <td>There is really not a lot of good material on ...</td>\n",
       "      <td>There is really not a lot of good material on ...</td>\n",
       "      <td>there is really not  lot of good material on t...</td>\n",
       "      <td>really not lot good material teaching martial ...</td>\n",
       "      <td>really not lot good material teaching martial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249384 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                            title  \\\n",
       "0            1                  mens ultrasheer   \n",
       "1            4          Surprisingly delightful   \n",
       "2            2     Works, but not as advertised   \n",
       "3            2                          Oh dear   \n",
       "4            2                  Incorrect disc!   \n",
       "...        ...                              ...   \n",
       "249379       3                    3 stars plus.   \n",
       "249380       3                          It's ok   \n",
       "249381       2          Not Great But Not Awful   \n",
       "249382       5              Greatest movie ever   \n",
       "249383       5  A cookbook for the imagination!   \n",
       "\n",
       "                                                     text language  \\\n",
       "0       This model may be ok for sedentary types, but ...       en   \n",
       "1       This is a fast read filled with unexpected hum...       en   \n",
       "2       I bought one of these chargers..the instructio...       en   \n",
       "3       I was excited to find a book ostensibly about ...       en   \n",
       "4       I am a big JVC fan, but I do not like this mod...       en   \n",
       "...                                                   ...      ...   \n",
       "249379  Spellbound was Paula Abduls peak, Although its...       en   \n",
       "249380  This is my second purchase of this album used,...       en   \n",
       "249381  This product would be a good buy for under $10...       en   \n",
       "249382  I love the movie the five heart beats I think ...       en   \n",
       "249383  There's really not a lot of good material on t...       en   \n",
       "\n",
       "       language_label  label  \\\n",
       "0             English      0   \n",
       "1             English      2   \n",
       "2             English      0   \n",
       "3             English      0   \n",
       "4             English      0   \n",
       "...               ...    ...   \n",
       "249379        English      1   \n",
       "249380        English      1   \n",
       "249381        English      0   \n",
       "249382        English      2   \n",
       "249383        English      2   \n",
       "\n",
       "                                             clean_text_1  \\\n",
       "0       This model may be ok for sedentary types, but ...   \n",
       "1       This is a fast read filled with unexpected hum...   \n",
       "2       I bought one of these chargers..the instructio...   \n",
       "3       I was excited to find a book ostensibly about ...   \n",
       "4       I am a big JVC fan, but I do not like this mod...   \n",
       "...                                                   ...   \n",
       "249379  Spellbound was Paula Abduls peak, Although its...   \n",
       "249380  This is my second purchase of this album used,...   \n",
       "249381  This product would be a good buy for under $. ...   \n",
       "249382  I love the movie the five heart beats I think ...   \n",
       "249383  There is really not a lot of good material on ...   \n",
       "\n",
       "                                             clean_text_2  \\\n",
       "0       This model may be ok for sedentary types , but...   \n",
       "1       This is a fast read filled with unexpected hum...   \n",
       "2       I bought one of these chargers .. the instruct...   \n",
       "3       I was excited to find a book ostensibly about ...   \n",
       "4       I am a big fan , but I do not like this model ...   \n",
       "...                                                   ...   \n",
       "249379  was Abduls peak , Although its her nd # album ...   \n",
       "249380  This is my purchase of this album used , lmao ...   \n",
       "249381  This product would be a good buy for under $ ....   \n",
       "249382  I love the movie the heart beats I think it wa...   \n",
       "249383  There is really not a lot of good material on ...   \n",
       "\n",
       "                                             clean_text_4  \\\n",
       "0       this model may be ok for sedentary types  but ...   \n",
       "1       this is  fast read filled with unexpected humo...   \n",
       "2        bought one of these chargers  the instruction...   \n",
       "3        was excited to find  book ostensibly about fe...   \n",
       "4        am  big fan  but  do not like this model   wa...   \n",
       "...                                                   ...   \n",
       "249379  was abduls peak  although its her nd  album  s...   \n",
       "249380  this is my purchase of this album used  lmao  ...   \n",
       "249381  this product would be  good buy for under   th...   \n",
       "249382   love the movie the heart beats  think it was ...   \n",
       "249383  there is really not  lot of good material on t...   \n",
       "\n",
       "                                             clean_text_5  \\\n",
       "0       model may ok sedentary type active get alot jo...   \n",
       "1       fast read filled unexpected humour profound in...   \n",
       "2       bought one charger instruction say light stay ...   \n",
       "3       excited find book ostensibly feminism volume n...   \n",
       "4       big fan not model suspiscious saw several unit...   \n",
       "...                                                   ...   \n",
       "249379  abduls peak nd album selling million copy thin...   \n",
       "249380  purchase album used lmao music style changed m...   \n",
       "249381  product would good buy completed robot go shor...   \n",
       "249382  love movie heart beat think one gratest movie ...   \n",
       "249383  really not lot good material teaching martial ...   \n",
       "\n",
       "                                               final_text  \n",
       "0       model may ok sedentary type active get alot jo...  \n",
       "1       fast read filled unexpected humour profound in...  \n",
       "2       bought one charger instruction say light stay ...  \n",
       "3       excited find book ostensibly feminism volume n...  \n",
       "4       big fan not model suspiscious saw several unit...  \n",
       "...                                                   ...  \n",
       "249379  abduls peak nd album selling million copy thin...  \n",
       "249380  purchase album used lmao music style changed m...  \n",
       "249381  product would good buy completed robot go shor...  \n",
       "249382  love movie heart beat think one gratest movie ...  \n",
       "249383  really not lot good material teaching martial ...  \n",
       "\n",
       "[249384 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get processed data\n",
    "df = pd.read_csv('preprocessed_data 2.csv', header=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect-Based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(clf_nb,open(\"model_naive_bayes.pkl\",'wb'))\n",
    "\n",
    "# Get pickle file for TF-IDF\n",
    "tfidf = pickle.load(open(\"tfidf.pkl\",'rb'))\n",
    "\n",
    "# Get pickle file for model\n",
    "model = pickle.load(open(\"model_naive_bayes.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cause and Effect is not that great of a band , but they seem to be a strong influence on Faith Assembly . Think droning male lead vocals , with synth lines straight from the bedroom studio . This would not be so bad in itself , but some of the lyrics either swim through so much cliche and/or are such cheesy groaners that I personally can not keep myself from poking for the track advance button on my player . If you are stuck in a circa   is synth pop rut and do not have terribly discerning tastes , this album is for you . For the rest of you , may I suggest something along the lines of ; is The Sunrise E.P. instead for contemporary synth pop of a similiarly mellow style . Cheers !\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "\n",
    "# sample_text = 4000\n",
    "\n",
    "# clean_text_2 - this is the 2nd cleaned text in the DF\n",
    "clean_text_2 = df['clean_text_2'][sample_text]\n",
    "\n",
    "# final_text - this is the final cleaned text after doing all preprocessing steps\n",
    "final_text = df['final_text'][sample_text]\n",
    "\n",
    "# this is an input from the user. keywords that they want to analyze.\n",
    "aspect_list = ['lyrics']\n",
    "\n",
    "print(clean_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names\n",
    "class_names = ['Negative', 'Positive']\n",
    "\n",
    "# Function to get the sentiment analysis for a specific text\n",
    "def SentimentAnalysis(inText):\n",
    "    \n",
    "    # Create a dataframe containing the input text\n",
    "    df_actual = pd.DataFrame([inText], columns=['final_text'])\n",
    "    \n",
    "    # Vectorization using TF-IDF\n",
    "    x_actual_matrix = tfidf.transform(df_actual['final_text'])\n",
    "    x_actual_tfidf_vector = x_actual_matrix.toarray()\n",
    "\n",
    "    # Predict the class: Negative/Positive\n",
    "    y_actual_pred = model.predict(x_actual_tfidf_vector)\n",
    "    \n",
    "    # Class probabilities\n",
    "    class_prob = model.predict_proba(x_actual_tfidf_vector)\n",
    "    \n",
    "    sentiment = class_names[y_actual_pred[0]]\n",
    "    \n",
    "    # Return the sentiment and class probabilities\n",
    "    return sentiment, class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the sentiment analysis for a specific aspect/keyword\n",
    "def AspectBasedSentimentAnalysis(inText):\n",
    "    \n",
    "    # Sentence tokenization\n",
    "    sent_list = sent_tokenize(str(inText))\n",
    "    \n",
    "    # Initialize dictionaries\n",
    "    aspect_class = {}\n",
    "    aspect_prob_diff = {}\n",
    "    \n",
    "    # Loop through all aspects/keywords submitted by user\n",
    "    for aspect in aspect_list:\n",
    "        \n",
    "        # For every aspect, loop through all sentences\n",
    "        for sentence in sent_list:\n",
    "            \n",
    "            # If aspect is in the sentence\n",
    "            if aspect in sentence:\n",
    "                \n",
    "                # Remove the aspect from the sentence\n",
    "                aspect_text =  sentence.replace(aspect, \"\")\n",
    "                \n",
    "                # Perform sentiment analysis on the sentence without the keyword\n",
    "                aspect_sentiment = SentimentAnalysis(aspect_text)\n",
    "                \n",
    "                # Get the difference between negative and positive class probabilities\n",
    "                # If the class probabilities are so close to each other (e.g., negative=0.49, positive=0.51), the difference is not too clear\n",
    "                prob_diff = abs(aspect_sentiment[1][0][0] - aspect_sentiment[1][0][1])\n",
    "                \n",
    "                # print(aspect_text,aspect_sentiment[0],aspect_sentiment[1][0])\n",
    "                \n",
    "                # This will output only if the probability difference at least 10 PPS\n",
    "                if (prob_diff >= 0.10) and (aspect_prob_diff.get(aspect) is not None and prob_diff > aspect_prob_diff.get(aspect) ) or ( (prob_diff >= 0.10) and (aspect_prob_diff.get(aspect) is None) ):\n",
    "                    \n",
    "                    # Update class dictionary\n",
    "                    aspect_class[aspect] = aspect_sentiment[0]\n",
    "                    \n",
    "                    # Update class probability dictionary\n",
    "                    aspect_prob_diff[aspect] = prob_diff\n",
    "                                        \n",
    "    # Return sentiment analysis for the aspect\n",
    "    return aspect_class                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Sentiment: Negative\n",
      "\n",
      "Aspect Sentiments:\n",
      "  lyrics: Negative\n"
     ]
    }
   ],
   "source": [
    "# Get overall sentiment\n",
    "overall_sentiment = SentimentAnalysis(final_text)\n",
    "\n",
    "# Perform aspect-based sentiment analysis\n",
    "aspect_sentiments = AspectBasedSentimentAnalysis(clean_text_2)\n",
    "\n",
    "# Display results\n",
    "print(\"Overall Sentiment:\", overall_sentiment[0])\n",
    "\n",
    "# Print results\n",
    "print(\"\\nAspect Sentiments:\")\n",
    "for aspect, sentiment in aspect_sentiments.items():\n",
    "    print(f\"  {aspect}: {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
